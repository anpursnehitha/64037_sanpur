{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "yOGWQ_BhMumu",
        "outputId": "bbf15a46-b62b-441f-c0fd-a79391d3023a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aece35b5-d6ae-4f77-85c9-a22f0500cfce\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aece35b5-d6ae-4f77-85c9-a22f0500cfce\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"snehithaanpur\",\"key\":\"d50bded4c181e2e220e57992394e3a65\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# To upload the kaggle.json file\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd-Et2whNSbt"
      },
      "outputs": [],
      "source": [
        "# Changing the prath to the .kaggle folder\n",
        "!cp kaggle.json ~/.kaggle/ \n",
        "#  Changing the permissions to perform read and write access\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH2ck_I3N0Ml",
        "outputId": "597daefa-fe0b-4294-b7e2-99f925abb9fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            "100% 811M/812M [00:35<00:00, 26.1MB/s]\n",
            "100% 812M/812M [00:35<00:00, 23.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Downloading the dogs-vs-cats dataset \n",
        "!kaggle competitions download -c dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5lQ_IZjN_KU"
      },
      "outputs": [],
      "source": [
        "# Unzipping dogs-vs-cats dataset file\n",
        "!unzip -qq dogs-vs-cats.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQHAsKLaOLea"
      },
      "outputs": [],
      "source": [
        "# Unzipping train sample \n",
        "!unzip -qq train.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0z-5klNOiId"
      },
      "source": [
        "Training from scratch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXip814XOVPH"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPQrijVDPKnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9b5786-78bf-418e-b9cd-1988170cad1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 178, 178, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 89, 89, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 87, 87, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 43, 43, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 41, 41, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 18, 18, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 9, 9, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 12545     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 991,041\n",
            "Trainable params: 991,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Building the model and running the model summary \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tg1tKWxgPj6J"
      },
      "outputs": [],
      "source": [
        "# Configuration of the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHVLKY7mPv56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52335f8-3887-4c69-df1f-7f55e6bfe65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Declaring the image size and batch size to read the images from train. validation and test directories\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pby5fiHOQrpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122a5392-efd2-45f7-e899-dc67d9b9793b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 17s 73ms/step - loss: 0.7021 - accuracy: 0.5025 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.6919 - accuracy: 0.5325 - val_loss: 0.6876 - val_accuracy: 0.5080\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.6928 - accuracy: 0.5760 - val_loss: 0.6736 - val_accuracy: 0.5830\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.6483 - accuracy: 0.6270 - val_loss: 0.6167 - val_accuracy: 0.6490\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 6s 86ms/step - loss: 0.6177 - accuracy: 0.6650 - val_loss: 0.6120 - val_accuracy: 0.6580\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.5805 - accuracy: 0.6970 - val_loss: 0.6090 - val_accuracy: 0.6810\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.5623 - accuracy: 0.7030 - val_loss: 0.5802 - val_accuracy: 0.7000\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.5275 - accuracy: 0.7475 - val_loss: 0.5548 - val_accuracy: 0.7290\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.5602 - val_accuracy: 0.7350\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 6s 84ms/step - loss: 0.4537 - accuracy: 0.8045 - val_loss: 0.6020 - val_accuracy: 0.7250\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.3868 - accuracy: 0.8305 - val_loss: 0.5735 - val_accuracy: 0.7320\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.3237 - accuracy: 0.8660 - val_loss: 0.6774 - val_accuracy: 0.7380\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2652 - accuracy: 0.8915 - val_loss: 1.5049 - val_accuracy: 0.6240\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.2423 - accuracy: 0.8970 - val_loss: 0.6902 - val_accuracy: 0.7490\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.1742 - accuracy: 0.9300 - val_loss: 0.9750 - val_accuracy: 0.7130\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.1569 - accuracy: 0.9450 - val_loss: 0.9126 - val_accuracy: 0.7390\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.1053 - accuracy: 0.9645 - val_loss: 1.4248 - val_accuracy: 0.7200\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0805 - accuracy: 0.9735 - val_loss: 1.0304 - val_accuracy: 0.7700\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.0686 - accuracy: 0.9775 - val_loss: 1.7106 - val_accuracy: 0.7320\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.0806 - accuracy: 0.9715 - val_loss: 1.2397 - val_accuracy: 0.7470\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0633 - accuracy: 0.9830 - val_loss: 1.3475 - val_accuracy: 0.7460\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.0638 - accuracy: 0.9810 - val_loss: 1.5428 - val_accuracy: 0.7220\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.0502 - accuracy: 0.9775 - val_loss: 2.4821 - val_accuracy: 0.6910\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0520 - accuracy: 0.9805 - val_loss: 1.9932 - val_accuracy: 0.6980\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.0487 - accuracy: 0.9885 - val_loss: 1.7922 - val_accuracy: 0.7180\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0538 - accuracy: 0.9825 - val_loss: 1.7394 - val_accuracy: 0.7410\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.0608 - accuracy: 0.9825 - val_loss: 1.8625 - val_accuracy: 0.7320\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.0567 - accuracy: 0.9800 - val_loss: 1.8604 - val_accuracy: 0.7470\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0391 - accuracy: 0.9835 - val_loss: 2.0435 - val_accuracy: 0.7190\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.0353 - accuracy: 0.9895 - val_loss: 1.8674 - val_accuracy: 0.7370\n"
          ]
        }
      ],
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J01Ro-KeSctR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f299f24b-3882-4080-f78e-77fd7f93b876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 33ms/step - loss: 0.5654 - accuracy: 0.7110\n",
            "Test accuracy: 0.711\n"
          ]
        }
      ],
      "source": [
        "# Testing the model \n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGVHqwbhZZS2"
      },
      "source": [
        "Data Augumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hoZKe4OZXpn"
      },
      "outputs": [],
      "source": [
        "# Declaring Data Augumentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lu9xlcX_Zji9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d2bf79-fff8-4afc-cee4-aacc73b46876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "# Building the model and configuing it \n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2DQqRw8Zyd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c61e7b54-4262-4f83-e26d-54f01384ec36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 18s 208ms/step - loss: 0.6959 - accuracy: 0.5100 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.6938 - accuracy: 0.5165 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 13s 209ms/step - loss: 0.6863 - accuracy: 0.5570 - val_loss: 0.6722 - val_accuracy: 0.5910\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 13s 208ms/step - loss: 0.7187 - accuracy: 0.5590 - val_loss: 0.6435 - val_accuracy: 0.6120\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.6392 - accuracy: 0.6350 - val_loss: 0.6133 - val_accuracy: 0.6710\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 15s 226ms/step - loss: 0.6255 - accuracy: 0.6505 - val_loss: 0.6911 - val_accuracy: 0.5590\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.6053 - accuracy: 0.6685 - val_loss: 0.6752 - val_accuracy: 0.6390\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 13s 207ms/step - loss: 0.6131 - accuracy: 0.6715 - val_loss: 0.6022 - val_accuracy: 0.6610\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.5928 - accuracy: 0.6950 - val_loss: 0.6375 - val_accuracy: 0.6240\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.5869 - accuracy: 0.7010 - val_loss: 0.5874 - val_accuracy: 0.6750\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 15s 222ms/step - loss: 0.5672 - accuracy: 0.7045 - val_loss: 0.8686 - val_accuracy: 0.5700\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.5603 - accuracy: 0.7170 - val_loss: 0.5842 - val_accuracy: 0.6720\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.5376 - accuracy: 0.7310 - val_loss: 0.6366 - val_accuracy: 0.6770\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 13s 207ms/step - loss: 0.5323 - accuracy: 0.7310 - val_loss: 0.9584 - val_accuracy: 0.5840\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.5271 - accuracy: 0.7370 - val_loss: 0.5690 - val_accuracy: 0.7100\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 13s 207ms/step - loss: 0.5038 - accuracy: 0.7670 - val_loss: 0.5552 - val_accuracy: 0.7140\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.4984 - accuracy: 0.7595 - val_loss: 0.6219 - val_accuracy: 0.6590\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 13s 207ms/step - loss: 0.4883 - accuracy: 0.7665 - val_loss: 0.5426 - val_accuracy: 0.7270\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.4882 - accuracy: 0.7710 - val_loss: 0.6267 - val_accuracy: 0.6840\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.4586 - accuracy: 0.7845 - val_loss: 0.5250 - val_accuracy: 0.7690\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.4682 - accuracy: 0.7845 - val_loss: 0.4891 - val_accuracy: 0.7710\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.4312 - accuracy: 0.7945 - val_loss: 0.5256 - val_accuracy: 0.7570\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.4337 - accuracy: 0.8115 - val_loss: 0.5689 - val_accuracy: 0.7070\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.4247 - accuracy: 0.7960 - val_loss: 0.5763 - val_accuracy: 0.6930\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 13s 202ms/step - loss: 0.4261 - accuracy: 0.8075 - val_loss: 0.5078 - val_accuracy: 0.7590\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.3937 - accuracy: 0.8270 - val_loss: 0.6702 - val_accuracy: 0.7350\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.4024 - accuracy: 0.8230 - val_loss: 0.4592 - val_accuracy: 0.7910\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.3791 - accuracy: 0.8240 - val_loss: 0.4694 - val_accuracy: 0.7910\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 13s 201ms/step - loss: 0.3589 - accuracy: 0.8375 - val_loss: 0.4623 - val_accuracy: 0.7930\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 13s 200ms/step - loss: 0.3620 - accuracy: 0.8405 - val_loss: 0.5024 - val_accuracy: 0.8040\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.3761 - accuracy: 0.8360 - val_loss: 0.4673 - val_accuracy: 0.8030\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.3583 - accuracy: 0.8490 - val_loss: 0.4591 - val_accuracy: 0.7970\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.3310 - accuracy: 0.8500 - val_loss: 0.4732 - val_accuracy: 0.7970\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 13s 202ms/step - loss: 0.3045 - accuracy: 0.8700 - val_loss: 0.4818 - val_accuracy: 0.8090\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.3101 - accuracy: 0.8635 - val_loss: 0.5095 - val_accuracy: 0.7990\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 13s 202ms/step - loss: 0.3093 - accuracy: 0.8705 - val_loss: 0.6212 - val_accuracy: 0.7960\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.2899 - accuracy: 0.8680 - val_loss: 0.5407 - val_accuracy: 0.7930\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.2853 - accuracy: 0.8770 - val_loss: 0.7444 - val_accuracy: 0.7520\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.2733 - accuracy: 0.8900 - val_loss: 0.5416 - val_accuracy: 0.8070\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.2451 - accuracy: 0.9020 - val_loss: 1.1370 - val_accuracy: 0.7090\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 13s 202ms/step - loss: 0.2528 - accuracy: 0.8970 - val_loss: 0.5176 - val_accuracy: 0.8260\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.2468 - accuracy: 0.9045 - val_loss: 0.6437 - val_accuracy: 0.7620\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.2367 - accuracy: 0.9075 - val_loss: 0.6226 - val_accuracy: 0.8200\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.2480 - accuracy: 0.8945 - val_loss: 0.5613 - val_accuracy: 0.8200\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 14s 208ms/step - loss: 0.2304 - accuracy: 0.8975 - val_loss: 0.6970 - val_accuracy: 0.7890\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.2289 - accuracy: 0.9160 - val_loss: 0.4897 - val_accuracy: 0.8250\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.2035 - accuracy: 0.9155 - val_loss: 0.5529 - val_accuracy: 0.8280\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1984 - accuracy: 0.9175 - val_loss: 0.7340 - val_accuracy: 0.7890\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 13s 202ms/step - loss: 0.2025 - accuracy: 0.9195 - val_loss: 0.5157 - val_accuracy: 0.8010\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1911 - accuracy: 0.9245 - val_loss: 0.6844 - val_accuracy: 0.8090\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 14s 216ms/step - loss: 0.1812 - accuracy: 0.9325 - val_loss: 0.5755 - val_accuracy: 0.8440\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1713 - accuracy: 0.9290 - val_loss: 0.6192 - val_accuracy: 0.8120\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 13s 201ms/step - loss: 0.1765 - accuracy: 0.9300 - val_loss: 0.6142 - val_accuracy: 0.8150\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.1748 - accuracy: 0.9290 - val_loss: 0.5810 - val_accuracy: 0.8150\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1747 - accuracy: 0.9355 - val_loss: 0.6665 - val_accuracy: 0.8000\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1655 - accuracy: 0.9310 - val_loss: 0.6263 - val_accuracy: 0.7930\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1550 - accuracy: 0.9455 - val_loss: 0.5993 - val_accuracy: 0.8250\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1466 - accuracy: 0.9395 - val_loss: 0.7936 - val_accuracy: 0.8230\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1572 - accuracy: 0.9445 - val_loss: 0.5533 - val_accuracy: 0.8290\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.1519 - accuracy: 0.9435 - val_loss: 0.8066 - val_accuracy: 0.8180\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1518 - accuracy: 0.9375 - val_loss: 0.7725 - val_accuracy: 0.8200\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.1472 - accuracy: 0.9415 - val_loss: 0.6347 - val_accuracy: 0.8270\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 13s 201ms/step - loss: 0.1341 - accuracy: 0.9485 - val_loss: 1.2502 - val_accuracy: 0.7840\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.1584 - accuracy: 0.9395 - val_loss: 0.8053 - val_accuracy: 0.8050\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 14s 218ms/step - loss: 0.1342 - accuracy: 0.9495 - val_loss: 0.8360 - val_accuracy: 0.8310\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.1243 - accuracy: 0.9540 - val_loss: 0.9112 - val_accuracy: 0.8390\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1049 - accuracy: 0.9610 - val_loss: 1.0779 - val_accuracy: 0.8070\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1386 - accuracy: 0.9565 - val_loss: 1.1762 - val_accuracy: 0.8210\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1617 - accuracy: 0.9460 - val_loss: 0.9278 - val_accuracy: 0.7720\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.1295 - accuracy: 0.9515 - val_loss: 0.7886 - val_accuracy: 0.8420\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 13s 202ms/step - loss: 0.1561 - accuracy: 0.9440 - val_loss: 0.7749 - val_accuracy: 0.8150\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1279 - accuracy: 0.9550 - val_loss: 0.9925 - val_accuracy: 0.8210\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.1190 - accuracy: 0.9555 - val_loss: 0.7576 - val_accuracy: 0.8120\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1131 - accuracy: 0.9570 - val_loss: 0.9403 - val_accuracy: 0.8440\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 14s 225ms/step - loss: 0.1423 - accuracy: 0.9560 - val_loss: 0.9287 - val_accuracy: 0.8190\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1038 - accuracy: 0.9685 - val_loss: 0.7764 - val_accuracy: 0.8250\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 13s 202ms/step - loss: 0.1237 - accuracy: 0.9655 - val_loss: 0.8494 - val_accuracy: 0.8260\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 13s 207ms/step - loss: 0.1164 - accuracy: 0.9575 - val_loss: 0.9926 - val_accuracy: 0.8380\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1258 - accuracy: 0.9570 - val_loss: 0.7245 - val_accuracy: 0.8380\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1294 - accuracy: 0.9560 - val_loss: 0.8161 - val_accuracy: 0.8220\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.0965 - accuracy: 0.9640 - val_loss: 0.8779 - val_accuracy: 0.8240\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 14s 225ms/step - loss: 0.1101 - accuracy: 0.9620 - val_loss: 0.9186 - val_accuracy: 0.8300\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1141 - accuracy: 0.9625 - val_loss: 1.1570 - val_accuracy: 0.8350\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1327 - accuracy: 0.9540 - val_loss: 0.8684 - val_accuracy: 0.8160\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1213 - accuracy: 0.9605 - val_loss: 0.9322 - val_accuracy: 0.8380\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.1209 - accuracy: 0.9600 - val_loss: 1.1047 - val_accuracy: 0.8190\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.0906 - accuracy: 0.9645 - val_loss: 1.4761 - val_accuracy: 0.7980\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1416 - accuracy: 0.9575 - val_loss: 0.9260 - val_accuracy: 0.8260\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1192 - accuracy: 0.9610 - val_loss: 0.9607 - val_accuracy: 0.8180\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1222 - accuracy: 0.9615 - val_loss: 1.5150 - val_accuracy: 0.8170\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1255 - accuracy: 0.9680 - val_loss: 1.2424 - val_accuracy: 0.8370\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 13s 203ms/step - loss: 0.1122 - accuracy: 0.9625 - val_loss: 1.1160 - val_accuracy: 0.8110\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1194 - accuracy: 0.9610 - val_loss: 1.3130 - val_accuracy: 0.7940\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 13s 205ms/step - loss: 0.1467 - accuracy: 0.9570 - val_loss: 0.7422 - val_accuracy: 0.8290\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1189 - accuracy: 0.9590 - val_loss: 0.8447 - val_accuracy: 0.8310\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1038 - accuracy: 0.9635 - val_loss: 1.0469 - val_accuracy: 0.8330\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 13s 201ms/step - loss: 0.1112 - accuracy: 0.9620 - val_loss: 0.9438 - val_accuracy: 0.8340\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 13s 202ms/step - loss: 0.1130 - accuracy: 0.9655 - val_loss: 0.8374 - val_accuracy: 0.8230\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 13s 206ms/step - loss: 0.0888 - accuracy: 0.9725 - val_loss: 0.9219 - val_accuracy: 0.8390\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 13s 204ms/step - loss: 0.1056 - accuracy: 0.9670 - val_loss: 0.9535 - val_accuracy: 0.8300\n"
          ]
        }
      ],
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3uHI9r7Z_nP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0f4346-fd8b-49dc-c614-66b341d3c7ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 33ms/step - loss: 0.4961 - accuracy: 0.7825\n",
            "Test accuracy: 0.783\n"
          ]
        }
      ],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyt3eQyJame3"
      },
      "source": [
        "Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "712NvGiKasRU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "6eb157ee-f5bb-4082-e269-fe1a2a66adc3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-e77c9beb09de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Training has 2000 samples, test has 1000 samples, and validation has 500 samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmake_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmake_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmake_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-e77c9beb09de>\u001b[0m in \u001b[0;36mmake_subset\u001b[0;34m(subset_name, start_index, end_index)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dog\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_base_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msubset_name\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"{category}.{i}.jpg\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'cats_vs_dogs_small_IncreasedTrainSample/train/cat'"
          ]
        }
      ],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "# Increasing the training sample from 1000 to 2000\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_IncreasedTrainSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 2000 samples, test has 1000 samples, and validation has 500 samples\n",
        "make_subset(\"train\", start_index=0, end_index=2000)\n",
        "make_subset(\"validation\", start_index=2000, end_index=2500)\n",
        "make_subset(\"test\", start_index=2500, end_index=3500)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7xkVzLkcqcp"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x46jZfxweJOT"
      },
      "outputs": [],
      "source": [
        "# Configuring the model \n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvb1ypjLeUV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3940bc4f-d586-4dbc-b5fe-66ca4e7c9336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 6s 65ms/step - loss: 0.7005 - accuracy: 0.5115 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.6938 - accuracy: 0.5235 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.6916 - accuracy: 0.5300 - val_loss: 0.6793 - val_accuracy: 0.6200\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.6771 - accuracy: 0.5820 - val_loss: 0.6777 - val_accuracy: 0.5620\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.6608 - accuracy: 0.6205 - val_loss: 0.7320 - val_accuracy: 0.5630\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.6262 - accuracy: 0.6560 - val_loss: 0.6066 - val_accuracy: 0.6720\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.5915 - accuracy: 0.6975 - val_loss: 0.5751 - val_accuracy: 0.6850\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.5613 - accuracy: 0.7090 - val_loss: 0.5661 - val_accuracy: 0.7040\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 6s 85ms/step - loss: 0.5371 - accuracy: 0.7300 - val_loss: 0.5755 - val_accuracy: 0.7070\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.4911 - accuracy: 0.7660 - val_loss: 0.6977 - val_accuracy: 0.6470\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.4685 - accuracy: 0.7845 - val_loss: 0.6459 - val_accuracy: 0.6580\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.4249 - accuracy: 0.8095 - val_loss: 0.6317 - val_accuracy: 0.7110\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.3749 - accuracy: 0.8350 - val_loss: 0.6290 - val_accuracy: 0.7110\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.3051 - accuracy: 0.8700 - val_loss: 0.6836 - val_accuracy: 0.7160\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.2681 - accuracy: 0.8880 - val_loss: 0.7549 - val_accuracy: 0.6800\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1936 - accuracy: 0.9160 - val_loss: 0.8954 - val_accuracy: 0.7090\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.1488 - accuracy: 0.9405 - val_loss: 1.3411 - val_accuracy: 0.6710\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.1361 - accuracy: 0.9485 - val_loss: 1.0175 - val_accuracy: 0.6850\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.0986 - accuracy: 0.9680 - val_loss: 1.2211 - val_accuracy: 0.7170\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.1153 - accuracy: 0.9620 - val_loss: 1.1141 - val_accuracy: 0.7340\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0658 - accuracy: 0.9775 - val_loss: 1.5063 - val_accuracy: 0.7050\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.0650 - accuracy: 0.9780 - val_loss: 1.5150 - val_accuracy: 0.7350\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.0641 - accuracy: 0.9780 - val_loss: 1.5641 - val_accuracy: 0.7190\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.0541 - accuracy: 0.9845 - val_loss: 2.2533 - val_accuracy: 0.7000\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.0438 - accuracy: 0.9855 - val_loss: 2.3006 - val_accuracy: 0.7080\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0807 - accuracy: 0.9760 - val_loss: 1.8943 - val_accuracy: 0.7120\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.0491 - accuracy: 0.9850 - val_loss: 2.0061 - val_accuracy: 0.7390\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.0437 - accuracy: 0.9815 - val_loss: 2.3232 - val_accuracy: 0.6990\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 2.3010 - val_accuracy: 0.7120\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 2.1963 - val_accuracy: 0.7030\n"
          ]
        }
      ],
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krnljuCXemqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e0866a-b971-484e-a410-38313331096b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 33ms/step - loss: 0.5616 - accuracy: 0.7130\n",
            "Test accuracy: 0.713\n"
          ]
        }
      ],
      "source": [
        "# Testing the model \n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0cJjLf1ewZr"
      },
      "source": [
        "Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXDPkrxkeskm"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "# Increasing the training sample from 1000 to 2000\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_OptimalTrainSamples1\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 1500 samples, test has 1000 samples, and validation has 500 samples\n",
        "# make_subset(\"train\", start_index=0, end_index=3500)\n",
        "# make_subset(\"validation\", start_index=2500, end_index=3000)\n",
        "# make_subset(\"test\", start_index=3000, end_index=4000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q144R-8SfUSZ"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbKZ53fMfh6G"
      },
      "outputs": [],
      "source": [
        "# Configuring the model \n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l65T9Yaf6Ss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2884b2f-d21e-4688-fe4b-ec330f576885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 files belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 10s 36ms/step - loss: 0.7077 - accuracy: 0.5217 - val_loss: 0.6779 - val_accuracy: 0.5450\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.6713 - accuracy: 0.6130 - val_loss: 0.6046 - val_accuracy: 0.6770\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.6141 - accuracy: 0.6800 - val_loss: 0.5686 - val_accuracy: 0.7230\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.5715 - accuracy: 0.7045 - val_loss: 0.7459 - val_accuracy: 0.6430\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.5298 - accuracy: 0.7347 - val_loss: 0.5585 - val_accuracy: 0.7240\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 9s 42ms/step - loss: 0.4790 - accuracy: 0.7682 - val_loss: 0.5680 - val_accuracy: 0.7350\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.4365 - accuracy: 0.7933 - val_loss: 0.5287 - val_accuracy: 0.7470\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.3746 - accuracy: 0.8300 - val_loss: 0.5222 - val_accuracy: 0.7560\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.3243 - accuracy: 0.8577 - val_loss: 0.5405 - val_accuracy: 0.7710\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.2568 - accuracy: 0.8845 - val_loss: 0.6835 - val_accuracy: 0.7670\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 12s 59ms/step - loss: 0.2007 - accuracy: 0.9178 - val_loss: 0.7115 - val_accuracy: 0.7840\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.1524 - accuracy: 0.9355 - val_loss: 0.6786 - val_accuracy: 0.8020\n",
            "Epoch 13/30\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.1204 - accuracy: 0.9523 - val_loss: 0.8565 - val_accuracy: 0.8000\n",
            "Epoch 14/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0976 - accuracy: 0.9640 - val_loss: 1.0357 - val_accuracy: 0.7860\n",
            "Epoch 15/30\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0979 - accuracy: 0.9688 - val_loss: 0.8735 - val_accuracy: 0.8010\n",
            "Epoch 16/30\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0963 - accuracy: 0.9725 - val_loss: 1.0003 - val_accuracy: 0.8010\n",
            "Epoch 17/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0748 - accuracy: 0.9755 - val_loss: 1.0397 - val_accuracy: 0.8090\n",
            "Epoch 18/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0791 - accuracy: 0.9740 - val_loss: 1.2148 - val_accuracy: 0.8010\n",
            "Epoch 19/30\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0641 - accuracy: 0.9803 - val_loss: 1.3411 - val_accuracy: 0.7990\n",
            "Epoch 20/30\n",
            "200/200 [==============================] - 9s 42ms/step - loss: 0.0825 - accuracy: 0.9762 - val_loss: 1.2197 - val_accuracy: 0.7950\n",
            "Epoch 21/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0565 - accuracy: 0.9820 - val_loss: 1.4136 - val_accuracy: 0.8030\n",
            "Epoch 22/30\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0564 - accuracy: 0.9843 - val_loss: 1.2854 - val_accuracy: 0.7950\n",
            "Epoch 23/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0668 - accuracy: 0.9835 - val_loss: 1.7370 - val_accuracy: 0.7840\n",
            "Epoch 24/30\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.0623 - accuracy: 0.9820 - val_loss: 1.4622 - val_accuracy: 0.8010\n",
            "Epoch 25/30\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0511 - accuracy: 0.9837 - val_loss: 1.7083 - val_accuracy: 0.7840\n",
            "Epoch 26/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0626 - accuracy: 0.9840 - val_loss: 1.6503 - val_accuracy: 0.8040\n",
            "Epoch 27/30\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0594 - accuracy: 0.9837 - val_loss: 1.7518 - val_accuracy: 0.7820\n",
            "Epoch 28/30\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0508 - accuracy: 0.9840 - val_loss: 1.9944 - val_accuracy: 0.8020\n",
            "Epoch 29/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0663 - accuracy: 0.9820 - val_loss: 2.1431 - val_accuracy: 0.8090\n",
            "Epoch 30/30\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0519 - accuracy: 0.9868 - val_loss: 2.2111 - val_accuracy: 0.7790\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3549 - accuracy: 0.8330\n",
            "Test accuracy: 0.833\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.3127 - accuracy: 0.9236 - val_loss: 0.6771 - val_accuracy: 0.8000\n",
            "Epoch 2/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.1165 - accuracy: 0.9610 - val_loss: 0.9039 - val_accuracy: 0.7970\n",
            "Epoch 3/30\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 0.0748 - accuracy: 0.9760 - val_loss: 1.2700 - val_accuracy: 0.8030\n",
            "Epoch 4/30\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0695 - accuracy: 0.9784 - val_loss: 1.2467 - val_accuracy: 0.8130\n",
            "Epoch 5/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0639 - accuracy: 0.9822 - val_loss: 1.6687 - val_accuracy: 0.7830\n",
            "Epoch 6/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0650 - accuracy: 0.9808 - val_loss: 1.8572 - val_accuracy: 0.7920\n",
            "Epoch 7/30\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0820 - accuracy: 0.9816 - val_loss: 1.6996 - val_accuracy: 0.8130\n",
            "Epoch 8/30\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0662 - accuracy: 0.9838 - val_loss: 1.7095 - val_accuracy: 0.7890\n",
            "Epoch 9/30\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.0744 - accuracy: 0.9824 - val_loss: 2.4955 - val_accuracy: 0.7890\n",
            "Epoch 10/30\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.0684 - accuracy: 0.9842 - val_loss: 1.8805 - val_accuracy: 0.8250\n",
            "Epoch 11/30\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0763 - accuracy: 0.9846 - val_loss: 1.8045 - val_accuracy: 0.8310\n",
            "Epoch 12/30\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0760 - accuracy: 0.9862 - val_loss: 2.5361 - val_accuracy: 0.8070\n",
            "Epoch 13/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0818 - accuracy: 0.9852 - val_loss: 2.0111 - val_accuracy: 0.7930\n",
            "Epoch 14/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0654 - accuracy: 0.9830 - val_loss: 2.2850 - val_accuracy: 0.7950\n",
            "Epoch 15/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0613 - accuracy: 0.9902 - val_loss: 2.1589 - val_accuracy: 0.8240\n",
            "Epoch 16/30\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0722 - accuracy: 0.9874 - val_loss: 2.5203 - val_accuracy: 0.8190\n",
            "Epoch 17/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0651 - accuracy: 0.9874 - val_loss: 2.3601 - val_accuracy: 0.8190\n",
            "Epoch 18/30\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.0632 - accuracy: 0.9882 - val_loss: 2.5509 - val_accuracy: 0.8120\n",
            "Epoch 19/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0833 - accuracy: 0.9854 - val_loss: 2.6319 - val_accuracy: 0.8130\n",
            "Epoch 20/30\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0837 - accuracy: 0.9870 - val_loss: 3.6005 - val_accuracy: 0.7900\n",
            "Epoch 21/30\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.0705 - accuracy: 0.9860 - val_loss: 2.7880 - val_accuracy: 0.8070\n",
            "Epoch 22/30\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.0853 - accuracy: 0.9874 - val_loss: 2.7624 - val_accuracy: 0.8180\n",
            "Epoch 23/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0794 - accuracy: 0.9866 - val_loss: 3.4157 - val_accuracy: 0.8110\n",
            "Epoch 24/30\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0710 - accuracy: 0.9894 - val_loss: 4.2890 - val_accuracy: 0.7860\n",
            "Epoch 25/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.1025 - accuracy: 0.9878 - val_loss: 4.4346 - val_accuracy: 0.7960\n",
            "Epoch 26/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0604 - accuracy: 0.9916 - val_loss: 3.7671 - val_accuracy: 0.8150\n",
            "Epoch 27/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0940 - accuracy: 0.9888 - val_loss: 4.2360 - val_accuracy: 0.8220\n",
            "Epoch 28/30\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0907 - accuracy: 0.9910 - val_loss: 4.5440 - val_accuracy: 0.8130\n",
            "Epoch 29/30\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0922 - accuracy: 0.9894 - val_loss: 4.3712 - val_accuracy: 0.8130\n",
            "Epoch 30/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0930 - accuracy: 0.9884 - val_loss: 4.7877 - val_accuracy: 0.7970\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.0449 - accuracy: 0.9880\n",
            "Test accuracy: 0.988\n",
            "Found 6000 files belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.4582 - accuracy: 0.9362 - val_loss: 1.1379 - val_accuracy: 0.7750\n",
            "Epoch 2/30\n",
            "300/300 [==============================] - 11s 37ms/step - loss: 0.1490 - accuracy: 0.9650 - val_loss: 1.4486 - val_accuracy: 0.8080\n",
            "Epoch 3/30\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.1131 - accuracy: 0.9772 - val_loss: 1.5708 - val_accuracy: 0.7890\n",
            "Epoch 4/30\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.0931 - accuracy: 0.9798 - val_loss: 2.3463 - val_accuracy: 0.8030\n",
            "Epoch 5/30\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.0812 - accuracy: 0.9827 - val_loss: 2.0018 - val_accuracy: 0.8220\n",
            "Epoch 6/30\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.0861 - accuracy: 0.9855 - val_loss: 2.6239 - val_accuracy: 0.8040\n",
            "Epoch 7/30\n",
            "300/300 [==============================] - 11s 37ms/step - loss: 0.0781 - accuracy: 0.9848 - val_loss: 2.4176 - val_accuracy: 0.8140\n",
            "Epoch 8/30\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.1035 - accuracy: 0.9810 - val_loss: 3.3314 - val_accuracy: 0.7940\n",
            "Epoch 9/30\n",
            "300/300 [==============================] - 11s 38ms/step - loss: 0.1047 - accuracy: 0.9840 - val_loss: 3.4999 - val_accuracy: 0.8020\n",
            "Epoch 10/30\n",
            "300/300 [==============================] - 11s 38ms/step - loss: 0.0755 - accuracy: 0.9890 - val_loss: 3.2983 - val_accuracy: 0.8070\n",
            "Epoch 11/30\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.1014 - accuracy: 0.9870 - val_loss: 3.5308 - val_accuracy: 0.8080\n",
            "Epoch 12/30\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.1010 - accuracy: 0.9863 - val_loss: 3.6142 - val_accuracy: 0.8110\n",
            "Epoch 13/30\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.1140 - accuracy: 0.9872 - val_loss: 3.4368 - val_accuracy: 0.8200\n",
            "Epoch 14/30\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.1122 - accuracy: 0.9848 - val_loss: 3.3716 - val_accuracy: 0.8100\n",
            "Epoch 15/30\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.0942 - accuracy: 0.9878 - val_loss: 4.2961 - val_accuracy: 0.8150\n",
            "Epoch 16/30\n",
            "300/300 [==============================] - 10s 34ms/step - loss: 0.1148 - accuracy: 0.9863 - val_loss: 4.1708 - val_accuracy: 0.8130\n",
            "Epoch 17/30\n",
            "300/300 [==============================] - 11s 37ms/step - loss: 0.0970 - accuracy: 0.9898 - val_loss: 4.6137 - val_accuracy: 0.8210\n",
            "Epoch 18/30\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.1288 - accuracy: 0.9882 - val_loss: 4.4059 - val_accuracy: 0.8040\n",
            "Epoch 19/30\n",
            "300/300 [==============================] - 11s 38ms/step - loss: 0.1365 - accuracy: 0.9863 - val_loss: 5.0407 - val_accuracy: 0.8180\n",
            "Epoch 20/30\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.1014 - accuracy: 0.9910 - val_loss: 5.8067 - val_accuracy: 0.8000\n",
            "Epoch 21/30\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.1694 - accuracy: 0.9887 - val_loss: 5.7057 - val_accuracy: 0.8080\n",
            "Epoch 22/30\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.1080 - accuracy: 0.9902 - val_loss: 5.2820 - val_accuracy: 0.8150\n",
            "Epoch 23/30\n",
            "300/300 [==============================] - 11s 38ms/step - loss: 0.1498 - accuracy: 0.9870 - val_loss: 6.4678 - val_accuracy: 0.8170\n",
            "Epoch 24/30\n",
            "300/300 [==============================] - 11s 38ms/step - loss: 0.1254 - accuracy: 0.9900 - val_loss: 5.4057 - val_accuracy: 0.8160\n",
            "Epoch 25/30\n",
            "300/300 [==============================] - 12s 37ms/step - loss: 0.1352 - accuracy: 0.9883 - val_loss: 5.4652 - val_accuracy: 0.8400\n",
            "Epoch 26/30\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.1454 - accuracy: 0.9867 - val_loss: 5.8726 - val_accuracy: 0.8190\n",
            "Epoch 27/30\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.1289 - accuracy: 0.9912 - val_loss: 6.2795 - val_accuracy: 0.8270\n",
            "Epoch 28/30\n",
            "300/300 [==============================] - 11s 37ms/step - loss: 0.1001 - accuracy: 0.9913 - val_loss: 5.5243 - val_accuracy: 0.8280\n",
            "Epoch 29/30\n",
            "300/300 [==============================] - 11s 38ms/step - loss: 0.1058 - accuracy: 0.9913 - val_loss: 7.0586 - val_accuracy: 0.7960\n",
            "Epoch 30/30\n",
            "300/300 [==============================] - 11s 36ms/step - loss: 0.1453 - accuracy: 0.9907 - val_loss: 6.2883 - val_accuracy: 0.8080\n",
            "63/63 [==============================] - 4s 55ms/step - loss: 0.0907 - accuracy: 0.9725\n",
            "Test accuracy: 0.973\n",
            "Found 7000 files belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.6282 - accuracy: 0.9346 - val_loss: 1.9890 - val_accuracy: 0.7990\n",
            "Epoch 2/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.2265 - accuracy: 0.9639 - val_loss: 1.6127 - val_accuracy: 0.8000\n",
            "Epoch 3/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1395 - accuracy: 0.9734 - val_loss: 2.4316 - val_accuracy: 0.7980\n",
            "Epoch 4/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1400 - accuracy: 0.9781 - val_loss: 2.3134 - val_accuracy: 0.8110\n",
            "Epoch 5/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1313 - accuracy: 0.9789 - val_loss: 2.7904 - val_accuracy: 0.8290\n",
            "Epoch 6/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1193 - accuracy: 0.9831 - val_loss: 2.7976 - val_accuracy: 0.8110\n",
            "Epoch 7/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1064 - accuracy: 0.9846 - val_loss: 3.2719 - val_accuracy: 0.7890\n",
            "Epoch 8/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1411 - accuracy: 0.9829 - val_loss: 5.3968 - val_accuracy: 0.7940\n",
            "Epoch 9/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1369 - accuracy: 0.9844 - val_loss: 4.5290 - val_accuracy: 0.7960\n",
            "Epoch 10/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1213 - accuracy: 0.9863 - val_loss: 4.3579 - val_accuracy: 0.8060\n",
            "Epoch 11/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1082 - accuracy: 0.9881 - val_loss: 3.8116 - val_accuracy: 0.8300\n",
            "Epoch 12/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1490 - accuracy: 0.9847 - val_loss: 4.3559 - val_accuracy: 0.7970\n",
            "Epoch 13/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.0965 - accuracy: 0.9890 - val_loss: 5.8005 - val_accuracy: 0.8000\n",
            "Epoch 14/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1480 - accuracy: 0.9871 - val_loss: 5.0261 - val_accuracy: 0.8180\n",
            "Epoch 15/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1510 - accuracy: 0.9870 - val_loss: 6.9153 - val_accuracy: 0.8120\n",
            "Epoch 16/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1596 - accuracy: 0.9866 - val_loss: 5.6247 - val_accuracy: 0.8200\n",
            "Epoch 17/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1972 - accuracy: 0.9869 - val_loss: 7.1685 - val_accuracy: 0.8270\n",
            "Epoch 18/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1605 - accuracy: 0.9881 - val_loss: 7.3324 - val_accuracy: 0.8220\n",
            "Epoch 19/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1634 - accuracy: 0.9900 - val_loss: 7.2162 - val_accuracy: 0.8060\n",
            "Epoch 20/30\n",
            "350/350 [==============================] - 13s 35ms/step - loss: 0.1907 - accuracy: 0.9899 - val_loss: 8.0416 - val_accuracy: 0.8250\n",
            "Epoch 21/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1388 - accuracy: 0.9909 - val_loss: 7.6042 - val_accuracy: 0.8270\n",
            "Epoch 22/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1838 - accuracy: 0.9883 - val_loss: 9.9419 - val_accuracy: 0.7870\n",
            "Epoch 23/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.2143 - accuracy: 0.9886 - val_loss: 11.9817 - val_accuracy: 0.8010\n",
            "Epoch 24/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1569 - accuracy: 0.9897 - val_loss: 10.2090 - val_accuracy: 0.8070\n",
            "Epoch 25/30\n",
            "350/350 [==============================] - 13s 35ms/step - loss: 0.1786 - accuracy: 0.9900 - val_loss: 8.3940 - val_accuracy: 0.8350\n",
            "Epoch 26/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1707 - accuracy: 0.9900 - val_loss: 9.9807 - val_accuracy: 0.8130\n",
            "Epoch 27/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1786 - accuracy: 0.9903 - val_loss: 10.4261 - val_accuracy: 0.8170\n",
            "Epoch 28/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.2489 - accuracy: 0.9889 - val_loss: 9.4125 - val_accuracy: 0.8250\n",
            "Epoch 29/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1828 - accuracy: 0.9900 - val_loss: 11.7488 - val_accuracy: 0.8130\n",
            "Epoch 30/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1407 - accuracy: 0.9904 - val_loss: 11.0455 - val_accuracy: 0.8220\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.0909 - accuracy: 0.9750\n",
            "Test accuracy: 0.975\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Train the model with varying training sample sizes\n",
        "sample_sizes = [3500,4000,4500,5000]\n",
        "history_dict = []\n",
        "for size in sample_sizes:\n",
        "    # Set up the training subset\n",
        "    make_subset(\"temp_train\", start_index=1500, end_index=size)\n",
        "    make_subset(\"validation\", start_index=size, end_index=size+500)\n",
        "    make_subset(\"test\", start_index=size+500, end_index=size+1500)\n",
        "    train_dataset = image_dataset_from_directory(\n",
        "      new_base_dir / \"temp_train\", \n",
        "      image_size=(180, 180), \n",
        "      batch_size=20)\n",
        "    # Using the callbacks function to monitor validation loss and running the model\n",
        "  \n",
        "    callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")]\n",
        "\n",
        "    history = model.fit(\n",
        "      train_dataset,\n",
        "      epochs=30,\n",
        "      validation_data=validation_dataset,\n",
        "      callbacks=callbacks)\n",
        "    \n",
        "    test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "    test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "    history_dict.append(test_acc)\n",
        "    print(f\"Test accuracy: {test_acc:.3f}\")  \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSlChBMvCo0Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klsCAaBc0T_B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e890062f-739b-4abb-db4d-b7dcb0a14847"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(sample_sizes, history_dict, 'bo-')\n",
        "plt.xlabel('Number of training samples')\n",
        "plt.ylabel('Test accuracy')\n",
        "plt.title('Effect of training sample size on CNN performance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0v2j8b6D0Vi7"
      },
      "outputs": [],
      "source": [
        "# shutil.rmtree(new_base_dir / \"temp_train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc8mKyfrI0PP"
      },
      "source": [
        "PreTrained Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7qLoU3zgKGi"
      },
      "source": [
        "Question 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBId1U_KOmvm"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_Pretrained\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 1500 samples, test has 500 samples, and validation has 500 samples\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEE6g1bNgNCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff89915d-b529-4279-e36b-0e678ddc271d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_21 (InputLayer)       [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Loading pre-trained weights to VGG16 model \n",
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))\n",
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvrlsOQJhbZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6faafe1e-ad30-4bf9-b20a-cb7d312a9966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 5, 5, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# Defining function to extract features and labels\n",
        "import numpy as np\n",
        "\n",
        "def get_features_and_labels(dataset):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    for images, labels in dataset:\n",
        "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
        "        features = conv_base.predict(preprocessed_images)\n",
        "        all_features.append(features)\n",
        "        all_labels.append(labels)\n",
        "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
        "# Extracting the features and labels from datasets\n",
        "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
        "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
        "test_features, test_labels =  get_features_and_labels(test_dataset)\n",
        "train_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59osmiCeJK6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ab62e7-e22b-4050-ee9e-064d55be65a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 9.0927 - accuracy: 0.9564 - val_loss: 1.3563 - val_accuracy: 0.9870\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 3.4211 - accuracy: 0.9775 - val_loss: 0.6536 - val_accuracy: 0.9950\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.8822 - accuracy: 0.9858 - val_loss: 0.3014 - val_accuracy: 0.9950\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.2669 - accuracy: 0.9890 - val_loss: 0.3193 - val_accuracy: 0.9950\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6366 - accuracy: 0.9922 - val_loss: 0.6106 - val_accuracy: 0.9920\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8781 - accuracy: 0.9913 - val_loss: 0.1561 - val_accuracy: 0.9970\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6042 - accuracy: 0.9923 - val_loss: 0.5746 - val_accuracy: 0.9940\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3618 - accuracy: 0.9954 - val_loss: 0.1786 - val_accuracy: 0.9970\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4177 - accuracy: 0.9954 - val_loss: 0.0123 - val_accuracy: 0.9990\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3558 - accuracy: 0.9952 - val_loss: 1.4690e-14 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1241 - accuracy: 0.9982 - val_loss: 4.1937e-33 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1770 - accuracy: 0.9972 - val_loss: 1.6382e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2140 - accuracy: 0.9971 - val_loss: 0.0462 - val_accuracy: 0.9990\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.1435 - accuracy: 0.9982 - val_loss: 9.8857e-37 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1616 - accuracy: 0.9975 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9975 - val_loss: 1.5882e-14 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1371 - accuracy: 0.9978 - val_loss: 0.0526 - val_accuracy: 0.9990\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9989 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0919 - accuracy: 0.9987 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0318 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Building the model \n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Running the callback function to monitor validation loss\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgvl1IFCKN79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b81235-769f-4572-a43d-d6faa2863559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9990\n",
            "Test accuracy: 0.999\n"
          ]
        }
      ],
      "source": [
        "# Testing the model \n",
        "test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng74u4XjKZJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff9e00c-65d7-40f7-f6df-5d5598bf76d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 26\n",
            "This is the number of trainable weights after freezing the conv base: 0\n"
          ]
        }
      ],
      "source": [
        "# Loading pre-trained weights to the VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "# Freezing the layers of the pretrained CNN \n",
        "conv_base.trainable = False\n",
        "\n",
        "# UnFreezing the layers of the pretrained CNN \n",
        "conv_base.trainable = True\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"before freezing the conv base:\", len(conv_base.trainable_weights))\n",
        "conv_base.trainable = False\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"after freezing the conv base:\", len(conv_base.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fhMcSlFLtfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a92e07-c25c-4e87-8ebd-ee83180fbafe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        " # Declaring Data Augumentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "# Building the model and configuring it\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Thxx8sGMuN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa92701-ae8e-4409-908d-dddc45701e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "350/350 [==============================] - 61s 165ms/step - loss: 12.9627 - accuracy: 0.9276 - val_loss: 2.9566 - val_accuracy: 0.9750\n",
            "Epoch 2/50\n",
            "350/350 [==============================] - 58s 163ms/step - loss: 6.2681 - accuracy: 0.9543 - val_loss: 2.8638 - val_accuracy: 0.9730\n",
            "Epoch 3/50\n",
            "350/350 [==============================] - 57s 161ms/step - loss: 4.0130 - accuracy: 0.9613 - val_loss: 1.9572 - val_accuracy: 0.9770\n",
            "Epoch 4/50\n",
            "350/350 [==============================] - 57s 161ms/step - loss: 2.6229 - accuracy: 0.9613 - val_loss: 1.3409 - val_accuracy: 0.9810\n",
            "Epoch 5/50\n",
            "350/350 [==============================] - 59s 168ms/step - loss: 1.7185 - accuracy: 0.9599 - val_loss: 0.6259 - val_accuracy: 0.9810\n",
            "Epoch 6/50\n",
            "350/350 [==============================] - 58s 165ms/step - loss: 1.1247 - accuracy: 0.9657 - val_loss: 0.4651 - val_accuracy: 0.9830\n",
            "Epoch 7/50\n",
            "350/350 [==============================] - 58s 164ms/step - loss: 0.9025 - accuracy: 0.9660 - val_loss: 0.3845 - val_accuracy: 0.9860\n",
            "Epoch 8/50\n",
            "350/350 [==============================] - 58s 165ms/step - loss: 0.7666 - accuracy: 0.9713 - val_loss: 0.7649 - val_accuracy: 0.9830\n",
            "Epoch 9/50\n",
            "350/350 [==============================] - 58s 164ms/step - loss: 0.9664 - accuracy: 0.9691 - val_loss: 0.5545 - val_accuracy: 0.9760\n",
            "Epoch 10/50\n",
            "350/350 [==============================] - 57s 163ms/step - loss: 0.7969 - accuracy: 0.9721 - val_loss: 0.8526 - val_accuracy: 0.9760\n",
            "Epoch 11/50\n",
            "350/350 [==============================] - 59s 169ms/step - loss: 0.8544 - accuracy: 0.9706 - val_loss: 1.4901 - val_accuracy: 0.9740\n",
            "Epoch 12/50\n",
            "350/350 [==============================] - 57s 162ms/step - loss: 0.9148 - accuracy: 0.9707 - val_loss: 0.9941 - val_accuracy: 0.9820\n",
            "Epoch 13/50\n",
            "350/350 [==============================] - 59s 167ms/step - loss: 0.8631 - accuracy: 0.9736 - val_loss: 1.1621 - val_accuracy: 0.9810\n",
            "Epoch 14/50\n",
            "350/350 [==============================] - 57s 162ms/step - loss: 0.8225 - accuracy: 0.9747 - val_loss: 1.7245 - val_accuracy: 0.9770\n",
            "Epoch 15/50\n",
            "350/350 [==============================] - 58s 164ms/step - loss: 0.8031 - accuracy: 0.9753 - val_loss: 2.1060 - val_accuracy: 0.9730\n",
            "Epoch 16/50\n",
            "350/350 [==============================] - 58s 165ms/step - loss: 0.8734 - accuracy: 0.9781 - val_loss: 1.3546 - val_accuracy: 0.9840\n",
            "Epoch 17/50\n",
            "350/350 [==============================] - 57s 162ms/step - loss: 0.7511 - accuracy: 0.9787 - val_loss: 1.9688 - val_accuracy: 0.9790\n",
            "Epoch 18/50\n",
            "350/350 [==============================] - 57s 162ms/step - loss: 0.8224 - accuracy: 0.9789 - val_loss: 1.5623 - val_accuracy: 0.9830\n",
            "Epoch 19/50\n",
            "350/350 [==============================] - 58s 165ms/step - loss: 1.1377 - accuracy: 0.9736 - val_loss: 1.3500 - val_accuracy: 0.9800\n",
            "Epoch 20/50\n",
            "350/350 [==============================] - 59s 167ms/step - loss: 0.8224 - accuracy: 0.9790 - val_loss: 2.2793 - val_accuracy: 0.9740\n",
            "Epoch 21/50\n",
            "350/350 [==============================] - 57s 162ms/step - loss: 0.8650 - accuracy: 0.9773 - val_loss: 1.8516 - val_accuracy: 0.9800\n",
            "Epoch 22/50\n",
            "350/350 [==============================] - 58s 165ms/step - loss: 0.9899 - accuracy: 0.9790 - val_loss: 0.8100 - val_accuracy: 0.9830\n",
            "Epoch 23/50\n",
            "350/350 [==============================] - 57s 162ms/step - loss: 0.8699 - accuracy: 0.9813 - val_loss: 1.5333 - val_accuracy: 0.9810\n",
            "Epoch 24/50\n",
            "350/350 [==============================] - 57s 163ms/step - loss: 0.7742 - accuracy: 0.9824 - val_loss: 1.6529 - val_accuracy: 0.9780\n",
            "Epoch 25/50\n",
            "350/350 [==============================] - 58s 165ms/step - loss: 0.9295 - accuracy: 0.9787 - val_loss: 1.7817 - val_accuracy: 0.9840\n",
            "Epoch 26/50\n",
            "350/350 [==============================] - 59s 167ms/step - loss: 0.8882 - accuracy: 0.9811 - val_loss: 1.7060 - val_accuracy: 0.9800\n",
            "Epoch 27/50\n",
            "350/350 [==============================] - 58s 164ms/step - loss: 0.7717 - accuracy: 0.9829 - val_loss: 1.5135 - val_accuracy: 0.9810\n",
            "Epoch 28/50\n",
            "350/350 [==============================] - 57s 162ms/step - loss: 0.7841 - accuracy: 0.9836 - val_loss: 1.6704 - val_accuracy: 0.9750\n",
            "Epoch 29/50\n",
            "350/350 [==============================] - 57s 163ms/step - loss: 0.8122 - accuracy: 0.9827 - val_loss: 2.0546 - val_accuracy: 0.9780\n",
            "Epoch 30/50\n",
            "350/350 [==============================] - 58s 165ms/step - loss: 0.8919 - accuracy: 0.9820 - val_loss: 1.7761 - val_accuracy: 0.9790\n",
            "Epoch 31/50\n",
            "350/350 [==============================] - 57s 163ms/step - loss: 0.7610 - accuracy: 0.9820 - val_loss: 1.9242 - val_accuracy: 0.9800\n",
            "Epoch 32/50\n",
            "350/350 [==============================] - 58s 166ms/step - loss: 0.8467 - accuracy: 0.9831 - val_loss: 1.7763 - val_accuracy: 0.9780\n",
            "Epoch 33/50\n",
            "350/350 [==============================] - 57s 161ms/step - loss: 0.8720 - accuracy: 0.9811 - val_loss: 1.8513 - val_accuracy: 0.9830\n",
            "Epoch 34/50\n",
            "350/350 [==============================] - 56s 161ms/step - loss: 0.7854 - accuracy: 0.9833 - val_loss: 1.6767 - val_accuracy: 0.9810\n",
            "Epoch 35/50\n",
            "350/350 [==============================] - 57s 162ms/step - loss: 0.8054 - accuracy: 0.9827 - val_loss: 2.6254 - val_accuracy: 0.9790\n",
            "Epoch 36/50\n",
            "350/350 [==============================] - 56s 161ms/step - loss: 0.7672 - accuracy: 0.9821 - val_loss: 3.8851 - val_accuracy: 0.9700\n",
            "Epoch 37/50\n",
            "350/350 [==============================] - 58s 165ms/step - loss: 0.8773 - accuracy: 0.9844 - val_loss: 2.7671 - val_accuracy: 0.9790\n",
            "Epoch 38/50\n",
            "350/350 [==============================] - 57s 162ms/step - loss: 0.8771 - accuracy: 0.9839 - val_loss: 1.8025 - val_accuracy: 0.9850\n",
            "Epoch 39/50\n",
            "350/350 [==============================] - 57s 163ms/step - loss: 0.7553 - accuracy: 0.9840 - val_loss: 2.4761 - val_accuracy: 0.9780\n",
            "Epoch 40/50\n",
            "350/350 [==============================] - 58s 164ms/step - loss: 0.7282 - accuracy: 0.9866 - val_loss: 2.7688 - val_accuracy: 0.9820\n",
            "Epoch 41/50\n",
            "350/350 [==============================] - 58s 165ms/step - loss: 0.8533 - accuracy: 0.9844 - val_loss: 2.6630 - val_accuracy: 0.9810\n",
            "Epoch 42/50\n",
            "350/350 [==============================] - 56s 161ms/step - loss: 1.0744 - accuracy: 0.9816 - val_loss: 2.2639 - val_accuracy: 0.9800\n",
            "Epoch 43/50\n",
            "350/350 [==============================] - 57s 161ms/step - loss: 0.6244 - accuracy: 0.9863 - val_loss: 2.4915 - val_accuracy: 0.9800\n",
            "Epoch 44/50\n",
            "350/350 [==============================] - 57s 163ms/step - loss: 1.0413 - accuracy: 0.9820 - val_loss: 2.6490 - val_accuracy: 0.9770\n",
            "Epoch 45/50\n",
            "350/350 [==============================] - 56s 161ms/step - loss: 0.8829 - accuracy: 0.9837 - val_loss: 2.5732 - val_accuracy: 0.9810\n",
            "Epoch 46/50\n",
            "350/350 [==============================] - 58s 163ms/step - loss: 0.9994 - accuracy: 0.9833 - val_loss: 2.5400 - val_accuracy: 0.9790\n",
            "Epoch 47/50\n",
            "350/350 [==============================] - 58s 165ms/step - loss: 0.8940 - accuracy: 0.9824 - val_loss: 3.4734 - val_accuracy: 0.9750\n",
            "Epoch 48/50\n",
            "350/350 [==============================] - 56s 160ms/step - loss: 0.7279 - accuracy: 0.9860 - val_loss: 3.6907 - val_accuracy: 0.9730\n",
            "Epoch 49/50\n",
            "350/350 [==============================] - 56s 161ms/step - loss: 0.8242 - accuracy: 0.9850 - val_loss: 2.5561 - val_accuracy: 0.9770\n",
            "Epoch 50/50\n",
            "350/350 [==============================] - 58s 166ms/step - loss: 0.7455 - accuracy: 0.9854 - val_loss: 2.4884 - val_accuracy: 0.9820\n"
          ]
        }
      ],
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=50,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-alBrfNNHpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1a0a68-c30c-412f-a5de-3222390dd31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 7s 101ms/step - loss: 0.4928 - accuracy: 0.9825\n",
            "Test accuracy: 0.983\n"
          ]
        }
      ],
      "source": [
        "# Testing the model \n",
        "test_model = keras.models.load_model(\n",
        "    \"feature_extraction_with_data_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UwJpqtONNJ8"
      },
      "outputs": [],
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_PretrainedIncreasedSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShIrzOAfM0O3"
      },
      "outputs": [],
      "source": [
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))\n",
        "# conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5DxHJNtSShj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef3eef2-337f-4213-fb13-74736922a0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 8.7215 - accuracy: 0.9546 - val_loss: 2.3165 - val_accuracy: 0.9790\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 3.3969 - accuracy: 0.9782 - val_loss: 0.9966 - val_accuracy: 0.9890\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 1.8710 - accuracy: 0.9850 - val_loss: 0.5527 - val_accuracy: 0.9940\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.3099 - accuracy: 0.9885 - val_loss: 0.5060 - val_accuracy: 0.9940\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.7670 - accuracy: 0.9914 - val_loss: 0.2423 - val_accuracy: 0.9970\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6977 - accuracy: 0.9937 - val_loss: 0.1875 - val_accuracy: 0.9980\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.6509 - accuracy: 0.9931 - val_loss: 0.1325 - val_accuracy: 0.9990\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.9950 - val_loss: 0.2029 - val_accuracy: 0.9980\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.2858 - accuracy: 0.9960 - val_loss: 0.0951 - val_accuracy: 0.9950\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1794 - accuracy: 0.9975 - val_loss: 4.8255e-27 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.2723 - accuracy: 0.9969 - val_loss: 3.3880e-17 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2869 - accuracy: 0.9960 - val_loss: 7.0943e-11 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1616 - accuracy: 0.9975 - val_loss: 4.4687e-36 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9984 - val_loss: 0.2701 - val_accuracy: 0.9970\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0627 - accuracy: 0.9985 - val_loss: 1.0677e-25 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9989 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1459 - accuracy: 0.9984 - val_loss: 0.0211 - val_accuracy: 0.9990\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1219 - accuracy: 0.9980 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1234 - accuracy: 0.9984 - val_loss: 1.6940e-10 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9994 - val_loss: 3.5870e-09 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "make_subset(\"train\", start_index=0, end_index=1500)\n",
        "make_subset(\"validation\", start_index=1500, end_index=2000)\n",
        "make_subset(\"test\", start_index=2000, end_index=3000)\n",
        "\n",
        "# Building the model \n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Running the callback function to monitor validation loss\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt93YJhsSWjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234ee114-4a09-4bf5-8db6-e0b46c7ac48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9995\n",
            "Test accuracy: 0.999\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Testing the model \n",
        "test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_PretrainedoptimalSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n"
      ],
      "metadata": {
        "id": "aJzRyFmO4g6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxa45oRyS_FI"
      },
      "outputs": [],
      "source": [
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2amNNKnKTwZx"
      },
      "outputs": [],
      "source": [
        "# Building the model \n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53MPNafGTxcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a310de2-b5ee-4076-8a6e-1dc04daad7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 7.9265 - accuracy: 0.9550 - val_loss: 1.2610 - val_accuracy: 0.9870\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 3.4520 - accuracy: 0.9788 - val_loss: 0.4244 - val_accuracy: 0.9940\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.7945 - accuracy: 0.9863 - val_loss: 0.3739 - val_accuracy: 0.9960\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.0880 - accuracy: 0.9888 - val_loss: 0.2849 - val_accuracy: 0.9970\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.7931 - accuracy: 0.9917 - val_loss: 0.0332 - val_accuracy: 0.9990\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4479 - accuracy: 0.9944 - val_loss: 0.0186 - val_accuracy: 0.9990\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5779 - accuracy: 0.9937 - val_loss: 1.7588e-13 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4635 - accuracy: 0.9947 - val_loss: 0.0983 - val_accuracy: 0.9980\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2514 - accuracy: 0.9960 - val_loss: 2.2708e-15 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1943 - accuracy: 0.9956 - val_loss: 0.3602 - val_accuracy: 0.9950\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2590 - accuracy: 0.9967 - val_loss: 0.0224 - val_accuracy: 0.9990\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1900 - accuracy: 0.9972 - val_loss: 0.0967 - val_accuracy: 0.9990\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2461 - accuracy: 0.9972 - val_loss: 6.2015e-17 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2382 - accuracy: 0.9970 - val_loss: 6.5735e-35 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1427 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2388 - accuracy: 0.9971 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9985 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1657 - accuracy: 0.9985 - val_loss: 9.7966e-08 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0686 - accuracy: 0.9986 - val_loss: 0.0675 - val_accuracy: 0.9980\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1161 - accuracy: 0.9983 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9995\n",
            "Test accuracy: 0.999\n",
            "Found 6000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0980 - accuracy: 0.9982 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0847 - accuracy: 0.9985 - val_loss: 3.9078e-34 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0752 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0475 - accuracy: 0.9994 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1243 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1077 - accuracy: 0.9992 - val_loss: 0.0925 - val_accuracy: 0.9990\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9993 - val_loss: 1.8392e-35 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9994 - val_loss: 0.0064 - val_accuracy: 0.9990\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0090 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0256 - accuracy: 0.9995 - val_loss: 0.0530 - val_accuracy: 0.9990\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0916 - accuracy: 0.9989 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0428 - accuracy: 0.9996 - val_loss: 2.0203e-07 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9989 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 7.0553e-12 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0104 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0183 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9995\n",
            "Test accuracy: 0.999\n",
            "Found 8000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0724 - accuracy: 0.9990 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0116 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9997 - val_loss: 1.4036e-37 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0442 - accuracy: 0.9992 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 3.0997e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 7.1256e-12 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0171 - accuracy: 0.9998 - val_loss: 6.7334e-38 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0302 - accuracy: 0.9997 - val_loss: 6.1371e-24 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0517 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9996 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9994 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 4.0146e-14 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9996 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 5.7627e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test accuracy: 1.000\n",
            "Found 10000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 1.3628e-14 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.4630e-13 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0194 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 4.7192e-24 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0212 - accuracy: 0.9996 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 1.4580e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.7269e-24 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 9.8726e-29 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0252 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.7407e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.0351e-35 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test accuracy: 1.000\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Train the model with varying training sample sizes\n",
        "sample_sizes = [2500,3000,4000,5000]\n",
        "history_dict = []\n",
        "for size in sample_sizes:\n",
        "    # Set up the training subset\n",
        "    make_subset(\"temp_train\", start_index=0, end_index=size)\n",
        "    make_subset(\"validation\", start_index=size, end_index=size+500)\n",
        "    make_subset(\"test\", start_index=size+500, end_index=size+1500)\n",
        "    train_dataset = image_dataset_from_directory(\n",
        "      new_base_dir / \"temp_train\", \n",
        "      image_size=(180, 180), \n",
        "      batch_size=20)\n",
        "    # Running the callback function to monitor validation loss\n",
        "    callbacks = [\n",
        "      keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")]\n",
        "\n",
        "    # Training the model\n",
        "    history = model.fit(\n",
        "      train_features, train_labels,\n",
        "      epochs=20,\n",
        "      validation_data=(val_features, val_labels),\n",
        "      callbacks=callbacks)\n",
        "    \n",
        "   # Testing the model \n",
        "    test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "    test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "    print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}